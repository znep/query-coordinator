#!/bin/sh
''''exec python -u -- "$0" ${1+"$@"} # '''
#
# Rewrite rules for Socrata, with specific emphasis on multiple domain names
# Our logic for handling static page caching was getting out of hand; we had
# so many RewriteCond statements to handle differing domain names that it
# quickly became un-maintainable. This script is an attempt at cleaning that
# up - it's launched via Apache as a RewriteMap.
#
# Apache will output a line to this program for each request that we read from
# stdin; we output the redirected URL to stdout.

import logging
import os
import os.path
import re
import string
import sys

DOMAIN_MAPPINGS = [
	{'match': re.compile('datagov'), 'site': 'datagov'},
	{'match': re.compile('datasf'), 'site': 'datasf'},
	{'match': re.compile('redwood'), 'site': 'redwood'},
	{'match': re.compile('chicago'), 'site': 'cityofchicago'},
	{'match': re.compile('nwpublicdata'), 'site': 'nwpublic'},
	{'match': re.compile('seattle'), 'site': 'cityofseattle'},
	{'match': re.compile('ohioag'), 'site': 'ohioag'},
	{'match': re.compile('austin'), 'site': 'cityofaustin'},
	{'match': re.compile('gov'), 'site': 'gov'}
]

def site_from_domain(domain):
	for matcher in DOMAIN_MAPPINGS:
		if matcher['match'].match(domain):
			return matcher['site']
	return 'socrata'

def parse_line(line):
	first_sep = line.find('!')
	if first_sep >= 0 and line.find('!', first_sep) >= 0:
		return line.split('!', 2)
	else:
		return ('/invalid/path', 'www.socrata.com', line)

def cache_path(document_root, site, path):
	path = path[1:] # Strip initial /
	cache_path = os.path.join(document_root, "cache", site, "%s.html" % path)
	logging.debug("Checking path %s", cache_path)
	if (os.path.isfile(cache_path)):
		logging.info("Cache hit: %s", cache_path)
		return "/cache/%s/%s.html" % (site, path)
	return None

if __name__ == '__main__':
	while 1:
		line = sys.stdin.readline()

		# Let's try REALLY hard to keep the server running. If this threw an
		# exception and quit, Apache gets into a state where it just returns an
		# unstyled page with HTTP 400 Bad Request, and needs to be restarted to
		# work again.
		try:
			line = string.rstrip(line)
			document_root, domain, path = parse_line(line)
			site = site_from_domain(domain)
			logging.debug("Document root: %s, Site: %s, Domain: %s, URL: %s",
				   document_root, site, domain, path)
			
			print cache_path(document_root, site, path) or \
				  cache_path(document_root, 'sitemaps', path) or \
				  path
		except:
			print "/"

